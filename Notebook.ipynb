{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype-based Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U scikit-fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import shap\n",
    "import pickle\n",
    "from abc import ABC, abstractmethod \n",
    "from itertools import cycle\n",
    "import skfuzzy as fuzz\n",
    "from scipy import linalg as la\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import MultiOutputMixin, BaseEstimator\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.6, style='whitegrid')\n",
    "import skfuzzy as fuzz\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".output_wrapper, .output {\n",
       "    height:auto !important;\n",
       "    max-height:10000px;  /* your desired max-height here */\n",
       "}\n",
       ".output_scroll {\n",
       "    box-shadow:none !important;\n",
       "    webkit-box-shadow:none !important;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".output_wrapper, .output {\n",
    "    height:auto !important;\n",
    "    max-height:10000px;  /* your desired max-height here */\n",
    "}\n",
    ".output_scroll {\n",
    "    box-shadow:none !important;\n",
    "    webkit-box-shadow:none !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ClustererWrapper super class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClustererWrapper(MultiOutputMixin, BaseEstimator, ABC):\n",
    "\n",
    "    def __init__(self, n_centers=3, seed=0):\n",
    "        \n",
    "        self.n_centers = n_centers\n",
    "        self.centroids = None\n",
    "        self.seed = seed\n",
    "    \n",
    "    @abstractmethod\n",
    "    def fit(self, X_train, Y_train=None):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "\n",
    "    def f_importance(self, X):\n",
    "\n",
    "        f_values = np.zeros(X.shape[1])\n",
    "        for xi in enumerate(self.centroids):\n",
    "            for xj in enumerate(self.centroids):\n",
    "                f_values += np.abs(xi[1]-xj[1])\n",
    "        \n",
    "        return f_values/np.sum(f_values)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy c-means wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FuzzyCMeansWrapper(ClustererWrapper):\n",
    "\n",
    "    def __init__(self, n_centers=3, seed=0):\n",
    "           \n",
    "        super().__init__(n_centers, seed)\n",
    "  \n",
    "    def fit(self, X_train, Y_train=None):\n",
    "        \n",
    "        self.centroids, _, _, _, _, _, _ = fuzz.cluster.cmeans(\n",
    "        X_train.T, self.n_centers, m=2, error=0.005, maxiter=1000, seed=self.seed)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "\n",
    "        u, _, _, _, _, _ = fuzz.cluster.cmeans_predict(\n",
    "            X.T, self.centroids, m=2, error=0.005, maxiter=1000, seed=self.seed)\n",
    "\n",
    "        return u.T\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeansWrapper(ClustererWrapper):\n",
    "\n",
    "    def __init__(self, n_centers=3, seed=0):\n",
    "\n",
    "        super().__init__(n_centers, seed)\n",
    "        self.kmeans = KMeans(self.n_centers, random_state=self.seed)\n",
    "    \n",
    "    def fit(self, X_train, Y_train=None):\n",
    "        \n",
    "        self.kmeans = self.kmeans.fit(X_train)\n",
    "        self.centroids = self.kmeans.cluster_centers_\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        X = np.array(X)\n",
    "        prediction_matrix = np.zeros((len(X), len(self.centroids)))\n",
    "\n",
    "        cluster_labels = self.kmeans.predict(X)\n",
    "        for i, label in enumerate(cluster_labels):\n",
    "            prediction_matrix[i, label] += 1\n",
    "            \n",
    "        return prediction_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral clustering wrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Note:```\n",
    "Not sure if the method really makes sense for Spectral Clustering, as the method assumes that the clusters are spherical.\n",
    "\n",
    "Another problem is that Sklearn's SpectralClustering class expects at least 2 point to perform the clustering. It would seem that ``shap.shap_values()`` function feeds the prediction function one sample at a time. \n",
    "\n",
    "Thus, the following error is thrown:  \n",
    "<img src=\"spectral_clustering_error.png\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralClusteringWrapper(ClustererWrapper):\n",
    "\n",
    "    def __init__(self, n_centers=3, seed=0):\n",
    "\n",
    "        super().__init__(n_centers, seed)\n",
    "        self.spectral_clustering = SpectralClustering(self.n_centers, random_state=self.seed)\n",
    "\n",
    "    def compute_centroids(self, X):\n",
    "        \n",
    "        centroids = np.zeros(self.n_centers)\n",
    "        for k in range(self.n_centers):\n",
    "            centroids[k] = np.mean([x for i, x in enumerate(X) if self.spectral_clustering.labels_[i] == k])\n",
    "\n",
    "        return centroids\n",
    "\n",
    "    def fit(self, X_train, Y_train=None):\n",
    "\n",
    "        X_train = np.array(X_train)\n",
    "        \n",
    "        self.spectral_clustering = self.spectral_clustering.fit(X_train)\n",
    "        self.centroids = self.compute_centroids(X_train)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        X = np.array(X)\n",
    "        prediction_matrix = np.zeros((len(X), len(self.centroids)))\n",
    "\n",
    "        cluster_labels = self.spectral_clustering.fit_predict(X)\n",
    "        for i, label in enumerate(cluster_labels):\n",
    "            prediction_matrix[i, label] += 1\n",
    "            \n",
    "        return prediction_matrix\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised algorithm wrapper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedAlgorithmWrapper():\n",
    "\n",
    "    def __init__(self, algorithm = KNeighborsClassifier()):\n",
    "        self.algorithm = algorithm\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.algorithm = self.algorithm.fit(X,y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        X = np.array(X)\n",
    "        label2id = {label : id for id, label in enumerate(self.algorithm.classes_)}\n",
    "        prediction_matrix = np.zeros((len(X), len(self.algorithm.classes_)))\n",
    "\n",
    "        predicted_labels = [label2id[label] for label in self.algorithm.predict(X)]\n",
    "        for i, label in enumerate(predicted_labels):\n",
    "            prediction_matrix[i, label] += 1\n",
    "        \n",
    "        return prediction_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(clustering_algo, supervised_algo, X, y, dataset_name, n_centers):\n",
    "\n",
    "    supervised_algo = supervised_algo.fit(X, y)\n",
    "\n",
    "    CLUSTERING_ALGORITHM_NAME = clustering_algo.__name__.replace('Wrapper', '')\n",
    "    SUPERVISED_ALGORITHM_NAME = supervised_algo.algorithm.__class__.__name__\n",
    "\n",
    "    # computing the clustering ground truth\n",
    "    clustering_algo = clustering_algo(n_centers, seed=0).fit(X.values)\n",
    "    temp = clustering_algo.predict(X.values)\n",
    "    y_true = np.argmax(clustering_algo.predict(X.values), axis=1)\n",
    "\n",
    "    errors_shap = [[]]\n",
    "\n",
    "    for algo, errors_list in zip([clustering_algo, supervised_algo], cycle(errors_shap)):\n",
    "\n",
    "        try:\n",
    "            # naming supervised algorithm\n",
    "            algo_name = algo.algorithm.__class__.__name__\n",
    "        \n",
    "        except AttributeError:\n",
    "            # naming clustering algorithm\n",
    "            algo_name = algo.__class__.__name__.replace('Wrapper', '')\n",
    "\n",
    "        try:\n",
    "            # load previously computed SHAP values if available\n",
    "            shap_values = pickle.load(open('shap_values/'+dataset_name+'_'+algo_name+'_shap.dat','rb'))\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            # compute the SHAP values from SCRATCH\n",
    "            explained_model = shap.KernelExplainer(algo.predict, X)\n",
    "            shap_values = explained_model.shap_values(X)\n",
    "            with open('shap_values/'+dataset_name+'_'+algo_name+'_shap.dat', 'wb') as file:\n",
    "                pickle.dump(shap_values, file)\n",
    "        \n",
    "        labels = ['c'+str(i) for i in range(1,n_centers+1)]\n",
    "        shap.summary_plot(shap_values=shap_values, features=X.columns, feature_names=None, \n",
    "                    plot_type='bar', class_names=labels, color=plt.get_cmap(\"tab20c\"), show=False)\n",
    "\n",
    "        plt.xlabel(\"SHAP value\", fontsize=18)\n",
    "        plt.tick_params(axis='x', labelsize=18)\n",
    "        plt.tick_params(axis='y', labelsize=18)\n",
    "        plt.gca().patch.set_edgecolor('lightgrey')  \n",
    "        plt.gca().patch.set_linewidth(1)\n",
    "        plt.legend(fontsize=18)\n",
    "        plt.savefig('shap_values/'+dataset_name+'_'+algo_name+'_figure.pdf', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        # computing the average SHAP values\n",
    "        ave_shap_values = np.zeros(shap_values[0].shape[1])\n",
    "        for shap_i in shap_values:\n",
    "            ave_shap_values += np.mean(np.absolute(shap_i), axis=0)\n",
    "\n",
    "        # sorting the features by their SHAP value\n",
    "        shap_df = pd.DataFrame(columns=['features','shap'])\n",
    "        shap_df['features'] = X.columns\n",
    "        shap_df['shap'] = ave_shap_values\n",
    "        shap_df.sort_values(by='shap', axis=0, ascending=False, inplace=True)\n",
    "        shap_labels = shap_df['features'].tolist()\n",
    "\n",
    "        errors_list = [1.0]\n",
    "        exclude = []\n",
    "\n",
    "        # computing the perturbation errors for SHAP\n",
    "        for fi in shap_labels:\n",
    "\n",
    "            df_temp = X.copy()\n",
    "            exclude.append(fi)\n",
    "\n",
    "            for column in exclude:\n",
    "                df_temp[column] = df_temp[column].mean()\n",
    "\n",
    "            y_pred = np.argmax(algo.predict(df_temp.values), axis=1)\n",
    "            errors_list.append(accuracy_score(y_true, y_pred))\n",
    "        \n",
    "        errors_shap.append(errors_list)\n",
    "    \n",
    "    errors_shap = [errors_list for errors_list in errors_shap if errors_list != []] \n",
    "        \n",
    "    # computing the results of the PBFI method\n",
    "    pbfi_df = pd.DataFrame(columns=['features','pfi'])\n",
    "    pbfi_df['features'] = X.columns\n",
    "    pbfi_df['pfi'] = clustering_algo.f_importance(X.values)\n",
    "    pbfi_df.sort_values(by='pfi', axis=0, ascending=False, inplace=True)\n",
    "    pbfi_labels = pbfi_df['features'].tolist()\n",
    "\n",
    "    errors_pbfi = [1.0]\n",
    "    exclude = []\n",
    "\n",
    "    # computing the perturbation errors for PFI\n",
    "    for fi in pbfi_labels:\n",
    "\n",
    "        df_temp = X.copy()\n",
    "        exclude.append(fi)\n",
    "\n",
    "        for column in exclude:\n",
    "            df_temp[column] = df_temp[column].mean()\n",
    "\n",
    "        y_pred = np.argmax(clustering_algo.predict(df_temp.values), axis=1)\n",
    "        errors_pbfi.append(accuracy_score(y_true, y_pred))\n",
    "\n",
    "\n",
    "    sns.lineplot(x = range(1,len(shap_labels)+2), y=errors_shap[0], marker='o', markersize=10, label = \"SHAP\")\n",
    "    sns.lineplot(x = range(1,len(pbfi_labels)+2), y=errors_pbfi, marker='D', markersize=10, label = \"PBFI\")\n",
    "    sns.lineplot(x = range(1,len(shap_labels)+2), y=errors_shap[1], marker='*', markersize=10, label = f\"SHAP_{SUPERVISED_ALGORITHM_NAME}\")\n",
    "    plt.tick_params(axis='x', labelsize=18)\n",
    "    plt.tick_params(axis='y', labelsize=18)\n",
    "    plt.xlabel('rank', fontsize=18)\n",
    "    plt.ylabel('accuracy', fontsize=18)\n",
    "\n",
    "    plt.gca().fill_between(range(1,len(shap_labels)+2), errors_shap[0], errors_pbfi, alpha=0.2, color='grey')\n",
    "\n",
    "    plt.savefig('feature_importance/error_'+dataset_name+'_'+CLUSTERING_ALGORITHM_NAME+'.pdf', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['ecoli', 'glass', 'heart-statlog', 'iris', 'liver-disorders', 'pima', 'vehicle', \n",
    "            'wine-quality-red', 'yeast', 'vertebra-column-2c', 'saheart', 'new-thyroid',\n",
    "            'echocardiogram', 'appendicitis', 'hayes-roth']\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "paper_rc = {'lines.linewidth': 1, 'lines.markersize': 7} \n",
    "sns.set_context('paper', font_scale=1.8, rc=paper_rc)\n",
    "\n",
    "for dataset in datasets:\n",
    "    \n",
    "    # loading the current dataset\n",
    "    df = pd.read_csv('datasets/'+dataset+'.csv')\n",
    "    n_centers = len(np.unique(df.values[:,-1]))\n",
    "    X = df.drop(df.columns[-1], axis='columns')\n",
    "    y = df.drop(df.columns[:-1], axis='columns')\n",
    "\n",
    "    for clustering_algo in [FuzzyCMeansWrapper, KMeansWrapper]:#, SpectralClusteringWrapper]:\n",
    "\n",
    "        pipeline(clustering_algo=clustering_algo, supervised_algo=SupervisedAlgorithmWrapper() ,X=X, y=y, dataset_name=dataset, n_centers=n_centers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
